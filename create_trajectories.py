from tracking.track import format_sample_result, AB3DMOT
import numpy as np
from pathlib import Path
import sys
import os
import os.path as osp
from tqdm import tqdm
import hydra
from omegaconf import DictConfig, OmegaConf
from lyft_dataset_sdk.lyftdataset import LyftDataset
from pyquaternion import Quaternion
import json
import matplotlib.pyplot as plt
# NUSCENES_TRACKING_NAMES = [
#   'car',
#   'pedestrian'
# ]
NUSCENES_TRACKING_NAMES = [
  'car'
]

def eprint(*args, **kwargs):
    print(*args, file=sys.stderr, **kwargs)
    
def display_args(args):
    eprint("========== ldls info ==========")
    eprint("host: {}".format(os.getenv('HOSTNAME')))
    eprint(OmegaConf.to_yaml(args))
    eprint("=======================================")

def get_pose(sample, nusc):
    pointsensor_token = sample['data']['LIDAR_TOP']
    pointsensor = nusc.get('sample_data', pointsensor_token)
    poserecord = nusc.get('ego_pose', pointsensor['ego_pose_token'])
    return np.array(poserecord['translation'])

@hydra.main(version_base='1.1', config_path="configs/", config_name="test_lyft.yaml")
def main(args: DictConfig):
    display_args(args)
    nusc = LyftDataset(data_path='/home/yy785/datasets/lyft_original/v1.01-train/', json_path='/home/yy785/datasets/lyft_original/v1.01-train/v1.01-train/', verbose=False)
    scenes = nusc.scene
    
    for scene in tqdm(scenes):
        results = {}
        # get samples for scene
        scene_token = scene['token']
        track_result_path = scene_token
        
        track_file_path = osp.join(args.data_paths.ldls_track_path, scene_token)
        with open(f'{track_file_path}.txt', 'r') as f:
            track_samples = f.readlines()
            track_samples = [sample.strip('\n') for sample in track_samples]
        
        # loop through samples
        mot_trackers = {tracking_name: AB3DMOT(args.covariance_id, tracking_name=tracking_name, use_angular_velocity=args.use_angular_velocity, tracking_nuscenes=True) for tracking_name in NUSCENES_TRACKING_NAMES}
#         if scene_token != '0a6839d6ee6804113bb5591ed99cc70ad883d0cff396e3aec5e76e718771b30e':
#             continue
        for sample_token in track_samples:
            sample = nusc.get('sample', sample_token)
    
#             sample_data_record = nusc.get("sample_data", sample['data']['LIDAR_TOP'])
#             ego_pose = nusc.get("ego_pose", sample_data_record['ego_pose_token'])
#             print(f'ego_pose: {ego_pose}')
            # get boxes generated by ldls for sample
            boxes_path = osp.join(args.data_paths.ldls_full_box_path, f"{sample_token}.npz")
            with np.load(boxes_path, allow_pickle=True) as f:
#                 pedestrian_boxes = f['pedestrian']
                boxes = f['car'].tolist()
    

            results[sample_token] = []
            dets = {tracking_name: [] for tracking_name in NUSCENES_TRACKING_NAMES}
            info = {tracking_name: [] for tracking_name in NUSCENES_TRACKING_NAMES}
#             trans = get_pose(sample, nusc)

            for box in boxes: # boxes are in global coordinate
                q = Quaternion(box.orientation)
                
                angle = q.angle if q.axis[2] > 0 else -q.angle
                #[h, w, l, x, y, z, rot_y]
                detection = np.array([
                  box.wlh[2], box.wlh[0], box.wlh[1], 
                  box.center[0],  box.center[1], box.center[2],
                  angle])

                information = np.array([box.score])
                dets[box.name].append(detection)
                info[box.name].append(information)
            
            dets_all = {tracking_name: {'dets': np.array(dets[tracking_name]), 'info': np.array(info[tracking_name])} for tracking_name in NUSCENES_TRACKING_NAMES}
            for tracking_name in NUSCENES_TRACKING_NAMES:
                if dets_all[tracking_name]['dets'].shape[0] > 0:
                    trackers = mot_trackers[tracking_name].update(dets_all[tracking_name], args.match_distance, args.match_threshold, args.match_algorithm, scene_token)
                    # (N, 9)
                    # (h, w, l, x, y, z, rot_y), tracking_id, tracking_score
                    for i in range(trackers.shape[0]):
                        sample_result = format_sample_result(sample_token, tracking_name, trackers[i])
                        results[sample_token].append(sample_result)
        # finished tracking all scenes, write output data
        output_data = {'meta': [], 'results': results}
        
        with open(track_result_path, 'w') as outfile:
            json.dump(output_data, outfile)
        

if __name__=="__main__":
    main()